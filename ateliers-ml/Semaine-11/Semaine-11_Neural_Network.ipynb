{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semaine 11 - Réseau de neurones de base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette semaine nous allons écrire un réseau de neurones de base, que nous allons entraîner afin qu'il inverse des séquences de bits. Si vous réussissez à l'implémenter, vous pourrez ensuite vous amuser à l'utiliser sur d'autres types de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations et initialisations de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'allons utiliser que numpy pour cet exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons un réseau à deux couches (l'input ne comptant pas pour une couche). Nous allons utiliser 300 séquences de bits pour l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nb de neurones sur chaque couche\n",
    "n_in = 10\n",
    "n_hidden = 100\n",
    "n_out = 10\n",
    "\n",
    "# Nb de 'training examples'\n",
    "m = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.5  # Learning rate\n",
    "epochs = 500  # nb iterations du gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des fonctions d'activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utiliserons la fonction tanh pour l'activation de la \"hidden layer\", et la sigmoïde pour la dernière couche. Implémentez-les si elle n'existent pas déjà dans numpy. Implémentez aussi la dérivée de l'une ou l'autre d'entre elles, le cas échéant.\n",
    "Attention! Les fonctions doivent pouvoir traiter des vecteurs ou des matrices en effectuant l'opération sur chaque élément de ces derniers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / ( 1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dérivée de tanh\n",
    "def tanh_prime(x):\n",
    "    return 1 - np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons écrire une fonction qui fait une activation puis une rétropropagation, puis renvoie l'erreur (loss) et le gradient (toutes ces variables qui commencent par d...). L'itération sur les 200 epochs se fera dans un deuxième temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, W1, W2, b1, b2):\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward\n",
    "        # First layer\n",
    "        Z1 = np.add(np.dot(W1, X), b1)\n",
    "        A1 = np.tanh(Z1)\n",
    "        # Second layer\n",
    "        Z2 = np.add(np.dot(W2, A1), b2)\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        # Backward\n",
    "        dZ2 = A2 - Y\n",
    "        dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "        db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        \n",
    "        dZ1 = np.multiply(np.dot(W2.T, dZ2), tanh_prime(Z1))\n",
    "        dW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "        db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "        # Parameter update (use the learning rate alpha here!)\n",
    "        W1 -= alpha * dW1\n",
    "        W2 -= alpha * dW2\n",
    "        b1 -= alpha * db1\n",
    "        b2 -= alpha * db2\n",
    "    \n",
    "        # Compute loss\n",
    "        loss = np.mean(-np.add(\n",
    "            np.multiply(\n",
    "                Y,\n",
    "                np.log(A2)\n",
    "            ),\n",
    "            np.multiply(\n",
    "                np.subtract(1, Y),\n",
    "                np.log(np.subtract(1, A2))\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        loss_history.append(loss)\n",
    "#         print(\"Epoch %d, Loss: %.8f\" % (epoch, loss))\n",
    "    \n",
    "    return loss_history, W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des paramètres du réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, certains paramètres sont initalisés à zéro, d'autres non..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(n_hidden, n_in) * 0.01\n",
    "W2 = np.random.randn(n_out, n_hidden) * 0.01\n",
    "b1 = np.zeros((n_hidden, 1))\n",
    "b2 = np.zeros((n_out, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des données d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici il s'agit créer 300 séries de 10 chiffres binaires (1 et 0) pour les X.\n",
    "Les Y seront ces mêmes séries, inversées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data generation\n",
    "X = np.random.binomial(1, 0.5, (n_in, m))\n",
    "Y = X ^ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancer l'entraînement du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, W1, W2, b1, b2 = train(X, Y, W1, W2, b1, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiser la décroissance de l'erreur sur un graphe (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1130a6be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0197757574459\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.show()\n",
    "print(loss_history[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation du réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrivez une petite fonction qui, à partir des activation de la dernière couche du réseau, produit un vecteur de 1 et de 0. Normalement il suffit de copier-coller quelque lignes de code et d'ajouter quelque chose à la fin. Attention, ici, contrairement à ce qu'on avait dans le MOOC, la dernière couche a 10 valeurs de sortie, et non pas une seule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneorzero(x):\n",
    "    if x > 0.5 :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "oneorzero = np.vectorize(oneorzero)\n",
    "\n",
    "def predict(X, W1, W2, b1, b2):\n",
    "    # First layer\n",
    "    Z1 = np.add(np.dot(W1, X), b1)\n",
    "    A1 = np.tanh(Z1)\n",
    "    # Second layer\n",
    "    Z2 = np.add(np.dot(W2, A1), b2)\n",
    "    A2 = oneorzero(sigmoid(Z2))\n",
    "    return A2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester la performance sur un seul exemple\n",
    "Ici on génère un seul exemple (une série de 10 chiffres binaires), puis on fait prédire son inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 1 1 1]]\n",
      "[[1 1 1 1 1 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.binomial(1, 0.5, (n_in,1))\n",
    "print(X.T)\n",
    "print(predict(X, W1, W2, b1, b2).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester la performance sur une série d'exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
